{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8e22026",
   "metadata": {},
   "source": [
    "# Word to Json Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4532b656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ JSON 변환 완료. 총 30개의 객관식(1-20)과 0개의 서술형(21-30) 질문이 ./evaluation_data_final_v3.json에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from docx import Document\n",
    "import re\n",
    "import uuid\n",
    "import os\n",
    "\n",
    "# --- 설정 변수 ---\n",
    "WORD_FILE_PATH = \"C:/RAG_DATA/evaluation/RAG_Quiz_Eng_v2.docx\"\n",
    "OUTPUT_JSON_PATH = \"./evaluation_data_final_v3.json\" # 최종 파일을 이 경로에 저장\n",
    "# -----------------\n",
    "\n",
    "def parse_docx_to_json_final_v3(word_file_path):\n",
    "    \"\"\"\n",
    "    Word 파일에서 질문-답변 쌍을 추출하여 JSON 구조로 변환합니다.\n",
    "    - 객관식(1-20)과 서술형(21-30)의 type을 정확하게 분류하고, 서술형 정답을 완전하게 추출\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        doc = Document(word_file_path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"오류: 파일을 찾을 수 없습니다. 경로를 확인해주세요: {word_file_path}\")\n",
    "        return None\n",
    "\n",
    "    all_data = []\n",
    "    current_question_data = {}\n",
    "    is_mcq_section = True\n",
    "    question_number = 1\n",
    "    \n",
    "    # 정규 표현식 패턴\n",
    "    option_pattern = re.compile(r\"^\\((A|B|C|D|E)\\)\")\n",
    "    # 질문 시작: '숫자.'로 시작하는 텍스트만 인식\n",
    "    question_start_pattern = re.compile(r\"^\\d+\\.\\s+\", re.IGNORECASE)\n",
    "    # 서술형 질문 제목/주제 부분 제거를 위한 패턴: '1. Transaction Concept: ...' -> 'Transaction Concept: ...'\n",
    "    descriptive_topic_pattern = re.compile(r\"^\\d+\\.\\s+\", re.IGNORECASE)\n",
    "    answer_tag_pattern = re.compile(r\"^Answer:\\s*(\\(?[A-E]\\)?|\\S.*)\", re.IGNORECASE)\n",
    "\n",
    "    # --- 파싱 로직 시작 ---\n",
    "    for paragraph in doc.paragraphs:\n",
    "        text = paragraph.text.strip()\n",
    "        \n",
    "        if not text:\n",
    "            continue\n",
    "            \n",
    "        # 1. Part II 섹션 진입 감지 (서술형 시작)\n",
    "        if text.startswith(\"Part II: Descriptive Questions\"):\n",
    "            # 객관식 20번 저장 (20번이 마지막에 처리되지 않았을 경우)\n",
    "            if current_question_data and current_question_data.get('type') == 'mcq':\n",
    "                 if not current_question_data.get('ground_truth_answer'):\n",
    "                    current_question_data['ground_truth_answer'] = \"Answer not found in parse\"\n",
    "                 all_data.append(current_question_data)\n",
    "                 \n",
    "            current_question_data = {} # 데이터 초기화\n",
    "            is_mcq_section = False\n",
    "            question_number = 21 # 서술형은 21번부터 시작\n",
    "            continue\n",
    "            \n",
    "        # 2. 새로운 질문 시작 감지\n",
    "        \n",
    "        if question_start_pattern.match(text):\n",
    "            # 이전 질문 저장 (새로운 질문 번호가 발견되면 저장)\n",
    "            if current_question_data:\n",
    "                if not current_question_data.get('ground_truth_answer'):\n",
    "                    current_question_data['ground_truth_answer'] = \"Answer not found in parse\"\n",
    "                # 객관식 질문이 서술형 섹션에 잘못 포함된 경우 answer_options 제거\n",
    "                if current_question_data.get('type') == 'descriptive' and 'answer_options' in current_question_data:\n",
    "                    del current_question_data['answer_options']\n",
    "                all_data.append(current_question_data)\n",
    "\n",
    "            # 새 질문 초기화\n",
    "            q_type = \"mcq\" if is_mcq_section else \"descriptive\"\n",
    "            \n",
    "            # 서술형 질문의 경우, \"1. \"과 같은 번호를 제거하여 질문만 남깁니다.\n",
    "            q_text = descriptive_topic_pattern.sub(\"\", text, 1) if not is_mcq_section else text\n",
    "\n",
    "            current_question_data = {\n",
    "                \"number\": question_number,\n",
    "                \"type\": q_type,\n",
    "                \"question\": q_text,\n",
    "                \"correct_node_id\": str(uuid.uuid4()),\n",
    "                \"ground_truth_context\": \"\",\n",
    "                \"ground_truth_answer\": \"\"\n",
    "            }\n",
    "            # 객관식일 경우에만 answer_options 리스트를 추가합니다.\n",
    "            if q_type == \"mcq\":\n",
    "                 current_question_data[\"answer_options\"] = []\n",
    "                 \n",
    "            question_number += 1\n",
    "            continue\n",
    "\n",
    "        # 3. 답변 옵션 파싱 (객관식에서만)\n",
    "        if current_question_data.get('type') == 'mcq' and option_pattern.match(text):\n",
    "            current_question_data['answer_options'].append(text)\n",
    "            continue\n",
    "            \n",
    "        # 4. 정답 파싱 및 연속 정답 처리\n",
    "        \n",
    "        answer_match = answer_tag_pattern.match(text)\n",
    "        \n",
    "        if answer_match and current_question_data and not current_question_data.get('ground_truth_answer'):\n",
    "            answer_content = answer_match.group(1).strip()\n",
    "            \n",
    "            if current_question_data['type'] == 'mcq':\n",
    "                # 객관식 정답 처리 (예: Answer: (C))\n",
    "                current_question_data['ground_truth_answer'] = f\"({answer_content.upper()})\" if len(answer_content) == 1 else answer_content\n",
    "                continue\n",
    "            \n",
    "            if current_question_data['type'] == 'descriptive':\n",
    "                # 서술형 정답 처리 (시작)\n",
    "                current_question_data['ground_truth_answer'] = answer_content\n",
    "                continue\n",
    "                \n",
    "        # 서술형 정답 연속 파싱\n",
    "        if current_question_data and current_question_data.get('type') == 'descriptive' and current_question_data.get('ground_truth_answer'):\n",
    "            # 다음 질문이나 새로운 'Answer:' 태그가 아닌 경우에만 텍스트를 정답에 추가\n",
    "            if not question_start_pattern.match(text) and not answer_tag_pattern.match(text):\n",
    "                current_question_data['ground_truth_answer'] += \" \" + text\n",
    "                continue\n",
    "                \n",
    "    # 5. 마지막 질문 저장\n",
    "    if current_question_data:\n",
    "        if not current_question_data.get('ground_truth_answer'):\n",
    "            current_question_data['ground_truth_answer'] = \"Answer not found in parse\"\n",
    "            \n",
    "        if current_question_data['type'] == 'descriptive' and 'answer_options' in current_question_data:\n",
    "            del current_question_data['answer_options']\n",
    "            \n",
    "        all_data.append(current_question_data)\n",
    "\n",
    "    # 최종 JSON 객체 생성 및 파일 저장\n",
    "    final_json = {\"mcq\": [data for data in all_data if data['type'] == 'mcq'], \n",
    "                  \"descriptive\": [data for data in all_data if data['type'] == 'descriptive']}\n",
    "    \n",
    "    with open(OUTPUT_JSON_PATH, 'w', encoding='utf-8') as f:\n",
    "        json.dump(final_json, f, ensure_ascii=False, indent=4)\n",
    "        \n",
    "    print(f\"\\n✅ JSON 변환 완료. 총 {len(final_json['mcq'])}개의 객관식(1-20)과 {len(final_json['descriptive'])}개의 서술형(21-30) 질문이 {OUTPUT_JSON_PATH}에 저장되었습니다.\")\n",
    "    \n",
    "    return final_json\n",
    "\n",
    "evaluation_data_final = parse_docx_to_json_final_v2(WORD_FILE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf31600",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9bc9006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading NLTK resource: wordnet\n",
      "Downloading NLTK resource: omw-1.4\n",
      "Loading quiz data from C:/RAG_DATA/evaluation/RAG_Quiz_Eng_with_IDs.json...\n",
      "DEBUG: Keys found in JSON file: ['mcq', 'essay']\n",
      "Found 12 models. Starting comprehensive evaluation...\n",
      "\n",
      "Evaluating: baseline...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  MCQ (baseline): 100%|██████████| 20/20 [00:40<00:00,  2.03s/it]\n",
      "  Desc (baseline):   0%|          | 0/10 [00:00<?, ?it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (baseline):  10%|█         | 1/10 [00:09<01:21,  9.06s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (baseline):  20%|██        | 2/10 [00:13<00:49,  6.24s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (baseline):  30%|███       | 3/10 [00:16<00:34,  4.93s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (baseline):  40%|████      | 4/10 [00:21<00:29,  4.91s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (baseline):  50%|█████     | 5/10 [00:26<00:24,  4.85s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (baseline):  60%|██████    | 6/10 [00:31<00:19,  4.91s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (baseline):  70%|███████   | 7/10 [00:36<00:14,  4.96s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (baseline):  80%|████████  | 8/10 [00:41<00:10,  5.02s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (baseline):  90%|█████████ | 9/10 [00:47<00:05,  5.17s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (baseline): 100%|██████████| 10/10 [00:50<00:00,  5.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  > [Retrieval] Recall@5: 0.0000\n",
      "  > [Generation] MCQ Acc: 0.8500\n",
      "  > [Generation] Desc BERTScore: 0.8771\n",
      "\n",
      "Evaluating: chunkoverlap_400...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  MCQ (chunkoverlap_400): 100%|██████████| 20/20 [00:41<00:00,  2.08s/it]\n",
      "  Desc (chunkoverlap_400):   0%|          | 0/10 [00:00<?, ?it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (chunkoverlap_400):  10%|█         | 1/10 [00:04<00:39,  4.40s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (chunkoverlap_400):  20%|██        | 2/10 [00:12<00:52,  6.60s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (chunkoverlap_400):  30%|███       | 3/10 [00:17<00:39,  5.64s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (chunkoverlap_400):  40%|████      | 4/10 [00:21<00:30,  5.13s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (chunkoverlap_400):  50%|█████     | 5/10 [00:25<00:24,  4.85s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (chunkoverlap_400):  60%|██████    | 6/10 [00:29<00:18,  4.62s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (chunkoverlap_400):  70%|███████   | 7/10 [00:35<00:14,  4.93s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (chunkoverlap_400):  80%|████████  | 8/10 [00:42<00:10,  5.45s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (chunkoverlap_400):  90%|█████████ | 9/10 [00:48<00:05,  5.78s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (chunkoverlap_400): 100%|██████████| 10/10 [00:54<00:00,  5.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  > [Retrieval] Recall@5: 0.1333\n",
      "  > [Generation] MCQ Acc: 0.8500\n",
      "  > [Generation] Desc BERTScore: 0.8956\n",
      "\n",
      "Evaluating: chunkoverlap_50...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  MCQ (chunkoverlap_50): 100%|██████████| 20/20 [00:38<00:00,  1.91s/it]\n",
      "  Desc (chunkoverlap_50):   0%|          | 0/10 [00:00<?, ?it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (chunkoverlap_50):  10%|█         | 1/10 [00:03<00:33,  3.69s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (chunkoverlap_50):  20%|██        | 2/10 [00:07<00:29,  3.70s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (chunkoverlap_50):  30%|███       | 3/10 [00:11<00:26,  3.72s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (chunkoverlap_50):  40%|████      | 4/10 [00:14<00:21,  3.57s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (chunkoverlap_50):  50%|█████     | 5/10 [00:18<00:18,  3.61s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (chunkoverlap_50):  60%|██████    | 6/10 [00:22<00:16,  4.01s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (chunkoverlap_50):  70%|███████   | 7/10 [00:29<00:14,  4.92s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (chunkoverlap_50):  80%|████████  | 8/10 [00:35<00:10,  5.21s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (chunkoverlap_50):  90%|█████████ | 9/10 [00:41<00:05,  5.33s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (chunkoverlap_50): 100%|██████████| 10/10 [00:47<00:00,  4.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  > [Retrieval] Recall@5: 0.2333\n",
      "  > [Generation] MCQ Acc: 0.8500\n",
      "  > [Generation] Desc BERTScore: 0.9030\n",
      "\n",
      "Evaluating: chunksize_2000...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  MCQ (chunksize_2000): 100%|██████████| 20/20 [00:29<00:00,  1.49s/it]\n",
      "  Desc (chunksize_2000):   0%|          | 0/10 [00:00<?, ?it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (chunksize_2000):  10%|█         | 1/10 [00:02<00:26,  2.95s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (chunksize_2000):  20%|██        | 2/10 [00:06<00:26,  3.32s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (chunksize_2000):  30%|███       | 3/10 [00:09<00:22,  3.19s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (chunksize_2000):  40%|████      | 4/10 [00:14<00:23,  3.99s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (chunksize_2000):  50%|█████     | 5/10 [00:18<00:18,  3.80s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (chunksize_2000):  60%|██████    | 6/10 [00:23<00:16,  4.19s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (chunksize_2000):  70%|███████   | 7/10 [00:28<00:13,  4.67s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (chunksize_2000):  80%|████████  | 8/10 [00:34<00:09,  4.86s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (chunksize_2000):  90%|█████████ | 9/10 [00:41<00:05,  5.51s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (chunksize_2000): 100%|██████████| 10/10 [00:45<00:00,  4.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  > [Retrieval] Recall@5: 0.1333\n",
      "  > [Generation] MCQ Acc: 0.8500\n",
      "  > [Generation] Desc BERTScore: 0.8999\n",
      "\n",
      "Evaluating: chunksize_500...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  MCQ (chunksize_500): 100%|██████████| 20/20 [00:30<00:00,  1.53s/it]\n",
      "  Desc (chunksize_500):   0%|          | 0/10 [00:00<?, ?it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (chunksize_500):  10%|█         | 1/10 [00:03<00:29,  3.33s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (chunksize_500):  20%|██        | 2/10 [00:06<00:26,  3.33s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (chunksize_500):  30%|███       | 3/10 [00:09<00:22,  3.21s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (chunksize_500):  40%|████      | 4/10 [00:13<00:19,  3.28s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (chunksize_500):  50%|█████     | 5/10 [00:16<00:16,  3.36s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (chunksize_500):  60%|██████    | 6/10 [00:21<00:14,  3.72s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (chunksize_500):  70%|███████   | 7/10 [00:25<00:12,  4.06s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (chunksize_500):  80%|████████  | 8/10 [00:30<00:08,  4.12s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (chunksize_500):  90%|█████████ | 9/10 [00:35<00:04,  4.49s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (chunksize_500): 100%|██████████| 10/10 [00:40<00:00,  4.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  > [Retrieval] Recall@5: 0.1667\n",
      "  > [Generation] MCQ Acc: 0.8500\n",
      "  > [Generation] Desc BERTScore: 0.8996\n",
      "\n",
      "Evaluating: default...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  MCQ (default): 100%|██████████| 20/20 [00:30<00:00,  1.54s/it]\n",
      "  Desc (default):   0%|          | 0/10 [00:00<?, ?it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (default):  10%|█         | 1/10 [00:05<00:46,  5.12s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (default):  20%|██        | 2/10 [00:09<00:36,  4.54s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (default):  30%|███       | 3/10 [00:12<00:28,  4.04s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (default):  40%|████      | 4/10 [00:16<00:22,  3.77s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (default):  50%|█████     | 5/10 [00:19<00:18,  3.63s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (default):  60%|██████    | 6/10 [00:24<00:16,  4.08s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (default):  70%|███████   | 7/10 [00:29<00:13,  4.47s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (default):  80%|████████  | 8/10 [00:35<00:09,  4.79s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (default):  90%|█████████ | 9/10 [00:40<00:04,  4.91s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (default): 100%|██████████| 10/10 [00:44<00:00,  4.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  > [Retrieval] Recall@5: 0.1667\n",
      "  > [Generation] MCQ Acc: 0.8500\n",
      "  > [Generation] Desc BERTScore: 0.8856\n",
      "\n",
      "Evaluating: gmmthreshold_0.05...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  MCQ (gmmthreshold_0.05): 100%|██████████| 20/20 [00:32<00:00,  1.60s/it]\n",
      "  Desc (gmmthreshold_0.05):   0%|          | 0/10 [00:00<?, ?it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (gmmthreshold_0.05):  10%|█         | 1/10 [00:03<00:27,  3.06s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (gmmthreshold_0.05):  20%|██        | 2/10 [00:06<00:27,  3.40s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (gmmthreshold_0.05):  30%|███       | 3/10 [00:09<00:23,  3.34s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (gmmthreshold_0.05):  40%|████      | 4/10 [00:13<00:20,  3.37s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (gmmthreshold_0.05):  50%|█████     | 5/10 [00:16<00:16,  3.40s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (gmmthreshold_0.05):  60%|██████    | 6/10 [00:21<00:14,  3.73s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (gmmthreshold_0.05):  70%|███████   | 7/10 [00:26<00:12,  4.09s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (gmmthreshold_0.05):  80%|████████  | 8/10 [00:31<00:08,  4.39s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (gmmthreshold_0.05):  90%|█████████ | 9/10 [00:35<00:04,  4.49s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (gmmthreshold_0.05): 100%|██████████| 10/10 [00:40<00:00,  4.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  > [Retrieval] Recall@5: 0.1667\n",
      "  > [Generation] MCQ Acc: 0.8500\n",
      "  > [Generation] Desc BERTScore: 0.8981\n",
      "\n",
      "Evaluating: gmmthreshold_0.3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  MCQ (gmmthreshold_0.3): 100%|██████████| 20/20 [00:31<00:00,  1.56s/it]\n",
      "  Desc (gmmthreshold_0.3):   0%|          | 0/10 [00:00<?, ?it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (gmmthreshold_0.3):  10%|█         | 1/10 [00:03<00:30,  3.42s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (gmmthreshold_0.3):  20%|██        | 2/10 [00:06<00:25,  3.13s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (gmmthreshold_0.3):  30%|███       | 3/10 [00:09<00:22,  3.15s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (gmmthreshold_0.3):  40%|████      | 4/10 [00:12<00:19,  3.28s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (gmmthreshold_0.3):  50%|█████     | 5/10 [00:15<00:15,  3.18s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (gmmthreshold_0.3):  60%|██████    | 6/10 [00:19<00:13,  3.39s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (gmmthreshold_0.3):  70%|███████   | 7/10 [00:24<00:11,  3.82s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (gmmthreshold_0.3):  80%|████████  | 8/10 [00:29<00:08,  4.31s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (gmmthreshold_0.3):  90%|█████████ | 9/10 [00:34<00:04,  4.29s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (gmmthreshold_0.3): 100%|██████████| 10/10 [00:39<00:00,  3.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  > [Retrieval] Recall@5: 0.1333\n",
      "  > [Generation] MCQ Acc: 0.8500\n",
      "  > [Generation] Desc BERTScore: 0.8952\n",
      "\n",
      "Evaluating: reductiondimension_20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  MCQ (reductiondimension_20): 100%|██████████| 20/20 [00:32<00:00,  1.63s/it]\n",
      "  Desc (reductiondimension_20):   0%|          | 0/10 [00:00<?, ?it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (reductiondimension_20):  10%|█         | 1/10 [00:03<00:35,  3.96s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (reductiondimension_20):  20%|██        | 2/10 [00:06<00:27,  3.39s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (reductiondimension_20):  30%|███       | 3/10 [00:10<00:25,  3.60s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (reductiondimension_20):  40%|████      | 4/10 [00:14<00:21,  3.51s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (reductiondimension_20):  50%|█████     | 5/10 [00:17<00:16,  3.29s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (reductiondimension_20):  60%|██████    | 6/10 [00:21<00:15,  3.82s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (reductiondimension_20):  70%|███████   | 7/10 [00:26<00:12,  4.22s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (reductiondimension_20):  80%|████████  | 8/10 [00:32<00:09,  4.52s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (reductiondimension_20):  90%|█████████ | 9/10 [00:36<00:04,  4.50s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (reductiondimension_20): 100%|██████████| 10/10 [00:41<00:00,  4.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  > [Retrieval] Recall@5: 0.1333\n",
      "  > [Generation] MCQ Acc: 0.8500\n",
      "  > [Generation] Desc BERTScore: 0.9037\n",
      "\n",
      "Evaluating: reductiondimension_5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  MCQ (reductiondimension_5): 100%|██████████| 20/20 [00:30<00:00,  1.53s/it]\n",
      "  Desc (reductiondimension_5):   0%|          | 0/10 [00:00<?, ?it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (reductiondimension_5):  10%|█         | 1/10 [00:04<00:36,  4.04s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (reductiondimension_5):  20%|██        | 2/10 [00:07<00:29,  3.67s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (reductiondimension_5):  30%|███       | 3/10 [00:10<00:24,  3.44s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (reductiondimension_5):  40%|████      | 4/10 [00:14<00:21,  3.51s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (reductiondimension_5):  50%|█████     | 5/10 [00:17<00:17,  3.57s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (reductiondimension_5):  60%|██████    | 6/10 [00:22<00:15,  3.88s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (reductiondimension_5):  70%|███████   | 7/10 [00:27<00:12,  4.21s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (reductiondimension_5):  80%|████████  | 8/10 [00:32<00:08,  4.39s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (reductiondimension_5):  90%|█████████ | 9/10 [00:36<00:04,  4.52s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (reductiondimension_5): 100%|██████████| 10/10 [00:41<00:00,  4.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  > [Retrieval] Recall@5: 0.1333\n",
      "  > [Generation] MCQ Acc: 0.8500\n",
      "  > [Generation] Desc BERTScore: 0.8945\n",
      "\n",
      "Evaluating: treeheight_10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  MCQ (treeheight_10): 100%|██████████| 20/20 [00:31<00:00,  1.58s/it]\n",
      "  Desc (treeheight_10):   0%|          | 0/10 [00:00<?, ?it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (treeheight_10):  10%|█         | 1/10 [00:03<00:30,  3.36s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (treeheight_10):  20%|██        | 2/10 [00:07<00:31,  3.88s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (treeheight_10):  30%|███       | 3/10 [00:11<00:28,  4.05s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (treeheight_10):  40%|████      | 4/10 [00:15<00:22,  3.75s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (treeheight_10):  50%|█████     | 5/10 [00:19<00:20,  4.01s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (treeheight_10):  60%|██████    | 6/10 [00:24<00:17,  4.43s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (treeheight_10):  70%|███████   | 7/10 [00:31<00:15,  5.01s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (treeheight_10):  80%|████████  | 8/10 [00:37<00:11,  5.60s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (treeheight_10):  90%|█████████ | 9/10 [00:42<00:05,  5.20s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (treeheight_10): 100%|██████████| 10/10 [00:47<00:00,  4.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  > [Retrieval] Recall@5: 0.1333\n",
      "  > [Generation] MCQ Acc: 0.8500\n",
      "  > [Generation] Desc BERTScore: 0.8928\n",
      "\n",
      "Evaluating: treeheight_2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  MCQ (treeheight_2): 100%|██████████| 20/20 [00:37<00:00,  1.86s/it]\n",
      "  Desc (treeheight_2):   0%|          | 0/10 [00:00<?, ?it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (treeheight_2):  10%|█         | 1/10 [00:04<00:39,  4.35s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (treeheight_2):  20%|██        | 2/10 [00:07<00:30,  3.77s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (treeheight_2):  30%|███       | 3/10 [00:11<00:25,  3.61s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (treeheight_2):  40%|████      | 4/10 [00:14<00:21,  3.52s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (treeheight_2):  50%|█████     | 5/10 [00:19<00:19,  3.94s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (treeheight_2):  60%|██████    | 6/10 [00:24<00:17,  4.39s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (treeheight_2):  70%|███████   | 7/10 [00:31<00:15,  5.28s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (treeheight_2):  80%|████████  | 8/10 [00:38<00:11,  5.68s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (treeheight_2):  90%|█████████ | 9/10 [00:42<00:05,  5.35s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  Desc (treeheight_2): 100%|██████████| 10/10 [00:48<00:00,  4.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  > [Retrieval] Recall@5: 0.1333\n",
      "  > [Generation] MCQ Acc: 0.8500\n",
      "  > [Generation] Desc BERTScore: 0.9015\n",
      "\n",
      "=== Final Evaluation Metrics ===\n",
      "                    Model                   Path  Retrieval_Recall@5  \\\n",
      "0                baseline               baseline            0.000000   \n",
      "1        chunkoverlap_400       chunkoverlap_400            0.133333   \n",
      "2         chunkoverlap_50        chunkoverlap_50            0.233333   \n",
      "3          chunksize_2000         chunksize_2000            0.133333   \n",
      "4           chunksize_500          chunksize_500            0.166667   \n",
      "5                 default                default            0.166667   \n",
      "6       gmmthreshold_0.05      gmmthreshold_0.05            0.166667   \n",
      "7        gmmthreshold_0.3       gmmthreshold_0.3            0.133333   \n",
      "8   reductiondimension_20  reductiondimension_20            0.133333   \n",
      "9    reductiondimension_5   reductiondimension_5            0.133333   \n",
      "10          treeheight_10          treeheight_10            0.133333   \n",
      "11           treeheight_2           treeheight_2            0.133333   \n",
      "\n",
      "    Retrieval_MRR  Retrieval_NDCG  MCQ_Accuracy  Desc_BERTScore  Desc_Rouge-L  \\\n",
      "0        0.000000        0.000000          0.85        0.877083      0.307076   \n",
      "1        0.111111        0.116667          0.85        0.895560      0.470347   \n",
      "2        0.167778        0.183926          0.85        0.903044      0.487373   \n",
      "3        0.111111        0.116667          0.85        0.899921      0.484788   \n",
      "4        0.119444        0.131023          0.85        0.899606      0.483918   \n",
      "5        0.116667        0.128712          0.85        0.885563      0.397048   \n",
      "6        0.100000        0.116409          0.85        0.898103      0.482231   \n",
      "7        0.111111        0.116667          0.85        0.895151      0.460959   \n",
      "8        0.088889        0.100000          0.85        0.903716      0.497969   \n",
      "9        0.081667        0.093918          0.85        0.894472      0.450517   \n",
      "10       0.086111        0.097689          0.85        0.892847      0.429667   \n",
      "11       0.088889        0.100000          0.85        0.901487      0.485272   \n",
      "\n",
      "    Desc_BLEU-1  Desc_METEOR  Desc_Token_F1  \n",
      "0      0.277557     0.255507       0.331456  \n",
      "1      0.457446     0.456709       0.479209  \n",
      "2      0.488172     0.458074       0.493874  \n",
      "3      0.484760     0.441201       0.502880  \n",
      "4      0.463541     0.431556       0.482362  \n",
      "5      0.382264     0.384696       0.419582  \n",
      "6      0.439059     0.427053       0.468371  \n",
      "7      0.424293     0.425352       0.475136  \n",
      "8      0.487228     0.460949       0.513572  \n",
      "9      0.438671     0.382623       0.444090  \n",
      "10     0.354176     0.417644       0.441360  \n",
      "11     0.466758     0.432900       0.475836  \n",
      "\n",
      "Metrics saved to: C:/RAG_DATA/evaluation/raptor_final_metrics.csv\n",
      "\n",
      "Successfully saved QA Logs to: C:/RAG_DATA/evaluation/raptor_qa_logs.docx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "import re\n",
    "import difflib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "\n",
    "# 자연어 처리 평가 지표 라이브러리\n",
    "import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "from rouge_score import rouge_scorer\n",
    "from bert_score import score as bert_score_func\n",
    "from collections import Counter\n",
    "\n",
    "# Word 문서 생성을 위한 라이브러리\n",
    "try:\n",
    "    from docx import Document\n",
    "    from docx.shared import Pt, RGBColor\n",
    "except ImportError:\n",
    "    print(\"Error: 'python-docx' library is missing. Please install it using 'pip install python-docx'\")\n",
    "    Document = None\n",
    "\n",
    "# LangChain 관련 임포트\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "# 경고 무시\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ==========================================\n",
    "# 1. 설정 및 API 키\n",
    "# ==========================================\n",
    "\n",
    "DATA_DIR = \"C:/RAG_DATA/data/processed_v2\"\n",
    "EVAL_FILE_PATH = \"C:/RAG_DATA/evaluation/RAG_Quiz_Eng_with_IDs.json\"\n",
    "RESULT_CSV_PATH = \"C:/RAG_DATA/evaluation/raptor_final_metrics.csv\"\n",
    "RESULT_DOCX_PATH = \"C:/RAG_DATA/evaluation/raptor_qa_logs.docx\" # Word 파일 저장 경로\n",
    "\n",
    "# OpenRouter / OpenAI 설정\n",
    "OPENROUTER_API_KEY = \"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\"\n",
    "OPENROUTER_API_BASE = \"https://openrouter.ai/api/v1\"\n",
    "\n",
    "os.environ[\"OPENROUTER_API_KEY\"] = OPENROUTER_API_KEY\n",
    "\n",
    "LLM_MODEL_NAME = \"google/gemini-2.5-flash-preview-09-2025\"\n",
    "EMBEDDING_MODEL_NAME = \"openai/text-embedding-3-small\"\n",
    "\n",
    "TOP_K = 5\n",
    "TEXT_SIMILARITY_THRESHOLD = 0.3\n",
    "\n",
    "# ==========================================\n",
    "# 2. NLTK 리소스 다운로드 및 설정\n",
    "# ==========================================\n",
    "def download_nltk_resources():\n",
    "    resources = ['punkt', 'wordnet', 'omw-1.4', 'punkt_tab']\n",
    "    for res in resources:\n",
    "        try:\n",
    "            nltk.data.find(f'tokenizers/{res}')\n",
    "        except LookupError:\n",
    "            print(f\"Downloading NLTK resource: {res}\")\n",
    "            nltk.download(res, quiet=True)\n",
    "        except ValueError:\n",
    "             pass \n",
    "\n",
    "download_nltk_resources()\n",
    "rouge_evaluator = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n",
    "\n",
    "# ==========================================\n",
    "# 3. [해결책 B] 검색 평가 함수\n",
    "# ==========================================\n",
    "\n",
    "def check_text_similarity(doc_text, gt_context, threshold=TEXT_SIMILARITY_THRESHOLD):\n",
    "    if not doc_text or not gt_context:\n",
    "        return False\n",
    "    \n",
    "    doc_text = doc_text.lower().strip()\n",
    "    gt_context = gt_context.lower().strip()\n",
    "    \n",
    "    if doc_text in gt_context or gt_context in doc_text:\n",
    "        return True\n",
    "\n",
    "    try:\n",
    "        doc_tokens = set(doc_text.split())\n",
    "        gt_tokens = set(gt_context.split())\n",
    "        if not gt_tokens or not doc_tokens:\n",
    "            jaccard = 0.0\n",
    "        else:\n",
    "            intersection = doc_tokens.intersection(gt_tokens)\n",
    "            union = doc_tokens.union(gt_tokens)\n",
    "            jaccard = len(intersection) / len(union)\n",
    "        \n",
    "        if jaccard >= threshold:\n",
    "            return True\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "    try:\n",
    "        ratio = difflib.SequenceMatcher(None, doc_text[:2000], gt_context[:2000]).ratio()\n",
    "        if ratio >= threshold:\n",
    "            return True\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    return False\n",
    "\n",
    "def calculate_retrieval_metrics(retrieved_docs, correct_node_id, ground_truth_context, k=TOP_K):\n",
    "    if not retrieved_docs:\n",
    "        return 0.0, 0.0, 0.0\n",
    "\n",
    "    retrieved_ids = [doc.metadata.get(\"node_id\") for doc in retrieved_docs]\n",
    "    \n",
    "    try:\n",
    "        rank_idx = retrieved_ids.index(correct_node_id)\n",
    "        rank = rank_idx + 1\n",
    "        return 1.0, 1.0/rank, 1.0/np.log2(rank + 1)\n",
    "    except ValueError:\n",
    "        pass\n",
    "\n",
    "    if ground_truth_context:\n",
    "        for i, doc in enumerate(retrieved_docs):\n",
    "            if check_text_similarity(doc.page_content, ground_truth_context, TEXT_SIMILARITY_THRESHOLD):\n",
    "                rank = i + 1\n",
    "                return 1.0, 1.0/rank, 1.0/np.log2(rank + 1)\n",
    "\n",
    "    return 0.0, 0.0, 0.0\n",
    "\n",
    "# ==========================================\n",
    "# 4. 답변 품질 평가 함수들\n",
    "# ==========================================\n",
    "\n",
    "def clean_text(text):\n",
    "    return text.strip().lower()\n",
    "\n",
    "def calculate_mcq_accuracy(prediction, ground_truth):\n",
    "    if not prediction or not ground_truth:\n",
    "        return 0.0\n",
    "    \n",
    "    pred_match = re.search(r'\\(([A-E])\\)', prediction)\n",
    "    gt_match = re.search(r'\\(([A-E])\\)', ground_truth)\n",
    "    \n",
    "    pred_char = pred_match.group(1) if pred_match else \"\"\n",
    "    gt_char = gt_match.group(1) if gt_match else \"\"\n",
    "    \n",
    "    if not pred_char:\n",
    "        for char in ['A', 'B', 'C', 'D', 'E']:\n",
    "            if f\"({char})\" in prediction or f\"{char}.\" in prediction:\n",
    "                pred_char = char\n",
    "                break\n",
    "                \n",
    "    if not gt_char:\n",
    "        gt_char = ground_truth.strip().replace(\"(\", \"\").replace(\")\", \"\")\n",
    "\n",
    "    return 1.0 if pred_char == gt_char else 0.0\n",
    "\n",
    "def calculate_token_f1(prediction, ground_truth):\n",
    "    pred_tokens = clean_text(prediction).split()\n",
    "    gt_tokens = clean_text(ground_truth).split()\n",
    "    \n",
    "    common = Counter(pred_tokens) & Counter(gt_tokens)\n",
    "    num_same = sum(common.values())\n",
    "    \n",
    "    if num_same == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    precision = 1.0 * num_same / len(pred_tokens)\n",
    "    recall = 1.0 * num_same / len(gt_tokens)\n",
    "    f1 = (2 * precision * recall) / (precision + recall)\n",
    "    return f1\n",
    "\n",
    "def calculate_descriptive_metrics(prediction, ground_truth):\n",
    "    metrics = {}\n",
    "    \n",
    "    try:\n",
    "        P, R, F1 = bert_score_func([prediction], [ground_truth], lang=\"en\", verbose=False)\n",
    "        metrics['BERTScore'] = F1.mean().item()\n",
    "    except Exception:\n",
    "        metrics['BERTScore'] = 0.0\n",
    "        \n",
    "    try:\n",
    "        scores = rouge_evaluator.score(ground_truth, prediction)\n",
    "        metrics['Rouge-L'] = scores['rougeL'].fmeasure\n",
    "    except Exception:\n",
    "        metrics['Rouge-L'] = 0.0\n",
    "        \n",
    "    pred_tokens = nltk.word_tokenize(prediction)\n",
    "    gt_tokens = nltk.word_tokenize(ground_truth)\n",
    "    \n",
    "    try:\n",
    "        chencherry = SmoothingFunction()\n",
    "        metrics['BLEU-1'] = sentence_bleu([gt_tokens], pred_tokens, weights=(1, 0, 0, 0), smoothing_function=chencherry.method1)\n",
    "    except Exception:\n",
    "        metrics['BLEU-1'] = 0.0\n",
    "        \n",
    "    try:\n",
    "        metrics['METEOR'] = meteor_score([gt_tokens], pred_tokens)\n",
    "    except Exception:\n",
    "        metrics['METEOR'] = 0.0\n",
    "        \n",
    "    metrics['Token_F1'] = calculate_token_f1(prediction, ground_truth)\n",
    "    return metrics\n",
    "\n",
    "# ==========================================\n",
    "# 5. 모델 로드 및 생성 함수\n",
    "# ==========================================\n",
    "\n",
    "def load_raptor_model(folder_path, index_name):\n",
    "    embeddings = OpenAIEmbeddings(\n",
    "        model=EMBEDDING_MODEL_NAME,\n",
    "        openai_api_key=OPENROUTER_API_KEY,\n",
    "        openai_api_base=OPENROUTER_API_BASE,\n",
    "        check_embedding_ctx_length=False\n",
    "    )\n",
    "    try:\n",
    "        vectorstore = FAISS.load_local(\n",
    "            folder_path=folder_path, \n",
    "            embeddings=embeddings, \n",
    "            index_name=index_name,\n",
    "            allow_dangerous_deserialization=True \n",
    "        )\n",
    "        return vectorstore\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model {index_name}: {e}\")\n",
    "        return None\n",
    "\n",
    "def generate_mcq_answer(llm, context, question, options):\n",
    "    options_str = \"\\n\".join(options)\n",
    "    prompt = f\"\"\"You are a helpful assistant. \n",
    "Read the following context and answer the multiple-choice question.\n",
    "Output ONLY the option letter (e.g., (A), (B), (C), (D), or (E)) that corresponds to the correct answer. Do not write any other text.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Options:\n",
    "{options_str}\n",
    "\n",
    "Correct Option:\"\"\"\n",
    "    messages = [HumanMessage(content=prompt)]\n",
    "    try:\n",
    "        response = llm.invoke(messages)\n",
    "        return response.content.strip()\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "def generate_descriptive_answer(llm, context, question):\n",
    "    prompt = f\"\"\"You are a helpful assistant. Answer the question based ONLY on the following context.\n",
    "Answer concisely and accurately.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\"\"\"\n",
    "    messages = [HumanMessage(content=prompt)]\n",
    "    try:\n",
    "        response = llm.invoke(messages)\n",
    "        return response.content.strip()\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "# ==========================================\n",
    "# 6. Word 저장 함수 (추가됨)\n",
    "# ==========================================\n",
    "def save_logs_to_docx(qa_logs, filepath):\n",
    "    \"\"\"\n",
    "    수집된 Q&A 로그를 Word 파일로 저장합니다.\n",
    "    \"\"\"\n",
    "    if Document is None:\n",
    "        print(\"Skipping Word export: python-docx not installed.\")\n",
    "        return\n",
    "\n",
    "    doc = Document()\n",
    "    doc.add_heading('RAPTOR Model Evaluation Logs', 0)\n",
    "\n",
    "    # 모델별로 그룹화\n",
    "    current_model = None\n",
    "    \n",
    "    for log in qa_logs:\n",
    "        # 모델 헤더 추가\n",
    "        if log['Model'] != current_model:\n",
    "            current_model = log['Model']\n",
    "            doc.add_page_break()\n",
    "            heading = doc.add_heading(f\"Model: {current_model}\", level=1)\n",
    "            heading.style.font.color.rgb = RGBColor(0, 50, 150) # 파란색 헤더\n",
    "\n",
    "        # 질문 섹션\n",
    "        p = doc.add_paragraph()\n",
    "        p.add_run(f\"[{log['Type']}] \").bold = True\n",
    "        p.add_run(log['Question'])\n",
    "\n",
    "        # 정답 및 예측\n",
    "        doc.add_paragraph(f\"Ground Truth: {log['Ground_Truth']}\", style='List Bullet')\n",
    "        \n",
    "        # 모델 답변 (강조)\n",
    "        p_ans = doc.add_paragraph(style='List Bullet')\n",
    "        run_ans = p_ans.add_run(f\"Generated: {log['Generated']}\")\n",
    "        run_ans.bold = True\n",
    "        run_ans.font.color.rgb = RGBColor(0, 100, 0) # 초록색\n",
    "        \n",
    "        # 점수 정보\n",
    "        if log['Score']:\n",
    "            doc.add_paragraph(f\"Score Info: {log['Score']}\", style='List Bullet 2')\n",
    "        \n",
    "        doc.add_paragraph(\"-\" * 50) # 구분선\n",
    "\n",
    "    try:\n",
    "        doc.save(filepath)\n",
    "        print(f\"\\nSuccessfully saved QA Logs to: {filepath}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving Word file: {e}\")\n",
    "\n",
    "# ==========================================\n",
    "# 7. 메인 실행 루프\n",
    "# ==========================================\n",
    "\n",
    "def main():\n",
    "    if not os.path.exists(EVAL_FILE_PATH):\n",
    "        print(f\"File not found: {EVAL_FILE_PATH}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Loading quiz data from {EVAL_FILE_PATH}...\")\n",
    "    with open(EVAL_FILE_PATH, 'r', encoding='utf-8') as f:\n",
    "        quiz_data = json.load(f)\n",
    "\n",
    "    keys = list(quiz_data.keys())\n",
    "    print(f\"DEBUG: Keys found in JSON file: {keys}\")\n",
    "\n",
    "    search_pattern = os.path.join(DATA_DIR, \"**/*.faiss\")\n",
    "    faiss_files = glob.glob(search_pattern, recursive=True)\n",
    "    faiss_files = [os.path.abspath(p) for p in faiss_files]\n",
    "    \n",
    "    if not faiss_files:\n",
    "        print(\"No models found.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Found {len(faiss_files)} models. Starting comprehensive evaluation...\")\n",
    "    \n",
    "    llm = ChatOpenAI(\n",
    "        model=LLM_MODEL_NAME,\n",
    "        openai_api_key=OPENROUTER_API_KEY,\n",
    "        openai_api_base=OPENROUTER_API_BASE,\n",
    "        temperature=0\n",
    "    )\n",
    "    \n",
    "    all_results = []\n",
    "    qa_logs = []  # Q&A 로그 수집용 리스트\n",
    "\n",
    "    for faiss_file in faiss_files:\n",
    "        folder_path = os.path.dirname(faiss_file)\n",
    "        index_name = os.path.splitext(os.path.basename(faiss_file))[0]\n",
    "        display_name = index_name\n",
    "        \n",
    "        print(f\"\\nEvaluating: {display_name}...\")\n",
    "        vectorstore = load_raptor_model(folder_path, index_name)\n",
    "        if not vectorstore:\n",
    "            continue\n",
    "            \n",
    "        retriever = vectorstore.as_retriever(search_kwargs={\"k\": TOP_K})\n",
    "        \n",
    "        mcq_scores = []\n",
    "        desc_metrics_sum = {\n",
    "            'BERTScore': 0, 'Rouge-L': 0, 'BLEU-1': 0, 'METEOR': 0, 'Token_F1': 0\n",
    "        }\n",
    "        retrieval_sum = {'Recall': 0, 'MRR': 0, 'NDCG': 0}\n",
    "        \n",
    "        desc_count = 0\n",
    "        total_retrieval_count = 0\n",
    "        \n",
    "        # --- 1. MCQ 평가 ---\n",
    "        mcq_key = None\n",
    "        for k in keys:\n",
    "            if \"mcq\" in k.lower():\n",
    "                mcq_key = k\n",
    "                break\n",
    "        \n",
    "        if mcq_key and isinstance(quiz_data[mcq_key], list):\n",
    "            for item in tqdm(quiz_data[mcq_key], desc=f\"  MCQ ({display_name})\"):\n",
    "                question = item.get(\"question\")\n",
    "                options = item.get(\"answer_options\", [])\n",
    "                ground_truth = item.get(\"ground_truth_answer\")\n",
    "                correct_node_id = item.get(\"correct_node_id\")\n",
    "                gt_context = item.get(\"ground_truth_context\", \"\")\n",
    "                \n",
    "                # 검색\n",
    "                try:\n",
    "                    docs = retriever.invoke(question)\n",
    "                    context = \"\\n\\n\".join([d.page_content for d in docs])\n",
    "                except:\n",
    "                    docs = []\n",
    "                    context = \"\"\n",
    "                \n",
    "                # Retrieval 평가\n",
    "                rec, mrr, ndcg = calculate_retrieval_metrics(docs, correct_node_id, gt_context, TOP_K)\n",
    "                retrieval_sum['Recall'] += rec\n",
    "                retrieval_sum['MRR'] += mrr\n",
    "                retrieval_sum['NDCG'] += ndcg\n",
    "                total_retrieval_count += 1\n",
    "                \n",
    "                # Generation 평가\n",
    "                pred = generate_mcq_answer(llm, context, question, options)\n",
    "                acc = calculate_mcq_accuracy(pred, ground_truth)\n",
    "                mcq_scores.append(acc)\n",
    "\n",
    "                # 로그 저장 (Word용)\n",
    "                qa_logs.append({\n",
    "                    \"Model\": display_name,\n",
    "                    \"Type\": \"MCQ\",\n",
    "                    \"Question\": question,\n",
    "                    \"Ground_Truth\": ground_truth,\n",
    "                    \"Generated\": pred,\n",
    "                    \"Score\": f\"Correct: {acc == 1.0}\"\n",
    "                })\n",
    "\n",
    "        else:\n",
    "            print(\"  [Warning] No MCQ questions found.\")\n",
    "\n",
    "        # --- 2. Descriptive 평가 ---\n",
    "        desc_key = None\n",
    "        possible_keys = [\"essay\", \"descriptive\", \"desc\", \"short_answer\", \"open_ended\", \"subjective\"]\n",
    "        for pk in possible_keys:\n",
    "            if pk in quiz_data:\n",
    "                desc_key = pk\n",
    "                break\n",
    "        if not desc_key:\n",
    "            for k in keys:\n",
    "                if any(pk in k.lower() for pk in possible_keys) and isinstance(quiz_data[k], list):\n",
    "                    desc_key = k\n",
    "                    break\n",
    "        \n",
    "        if desc_key:\n",
    "            for item in tqdm(quiz_data[desc_key], desc=f\"  Desc ({display_name})\"):\n",
    "                question = item.get(\"question\")\n",
    "                ground_truth = item.get(\"ground_truth_answer\") or item.get(\"answer\", \"\")\n",
    "                correct_node_id = item.get(\"correct_node_id\")\n",
    "                gt_context = item.get(\"ground_truth_context\", \"\")\n",
    "                \n",
    "                try:\n",
    "                    docs = retriever.invoke(question)\n",
    "                    context = \"\\n\\n\".join([d.page_content for d in docs])\n",
    "                except:\n",
    "                    docs = []\n",
    "                    context = \"\"\n",
    "\n",
    "                # Retrieval 평가\n",
    "                rec, mrr, ndcg = calculate_retrieval_metrics(docs, correct_node_id, gt_context, TOP_K)\n",
    "                retrieval_sum['Recall'] += rec\n",
    "                retrieval_sum['MRR'] += mrr\n",
    "                retrieval_sum['NDCG'] += ndcg\n",
    "                total_retrieval_count += 1\n",
    "                \n",
    "                # Generation 평가\n",
    "                pred = generate_descriptive_answer(llm, context, question)\n",
    "                metrics = calculate_descriptive_metrics(pred, ground_truth)\n",
    "                \n",
    "                for k, v in metrics.items():\n",
    "                    desc_metrics_sum[k] += v\n",
    "                desc_count += 1\n",
    "\n",
    "                # 로그 저장 (Word용)\n",
    "                qa_logs.append({\n",
    "                    \"Model\": display_name,\n",
    "                    \"Type\": \"Descriptive\",\n",
    "                    \"Question\": question,\n",
    "                    \"Ground_Truth\": ground_truth,\n",
    "                    \"Generated\": pred,\n",
    "                    \"Score\": f\"BERT: {metrics['BERTScore']:.2f} | Rouge: {metrics['Rouge-L']:.2f}\"\n",
    "                })\n",
    "\n",
    "        else:\n",
    "            print(f\"  [Warning] No descriptive questions found.\")\n",
    "        \n",
    "        # --- 결과 집계 ---\n",
    "        avg_mcq_acc = sum(mcq_scores)/len(mcq_scores) if mcq_scores else 0.0\n",
    "        \n",
    "        res_entry = {\n",
    "            \"Model\": display_name,\n",
    "            \"Path\": os.path.basename(folder_path),\n",
    "            \"MCQ_Accuracy\": avg_mcq_acc,\n",
    "            \"Desc_Count\": desc_count\n",
    "        }\n",
    "\n",
    "        # Retrieval Metrics 추가\n",
    "        if total_retrieval_count > 0:\n",
    "            res_entry[\"Retrieval_Recall@5\"] = retrieval_sum['Recall'] / total_retrieval_count\n",
    "            res_entry[\"Retrieval_MRR\"] = retrieval_sum['MRR'] / total_retrieval_count\n",
    "            res_entry[\"Retrieval_NDCG\"] = retrieval_sum['NDCG'] / total_retrieval_count\n",
    "        else:\n",
    "             res_entry[\"Retrieval_Recall@5\"] = 0.0\n",
    "             res_entry[\"Retrieval_MRR\"] = 0.0\n",
    "             res_entry[\"Retrieval_NDCG\"] = 0.0\n",
    "\n",
    "        # Descriptive Metrics 추가\n",
    "        if desc_count > 0:\n",
    "            for k, v in desc_metrics_sum.items():\n",
    "                res_entry[f\"Desc_{k}\"] = v / desc_count\n",
    "        else:\n",
    "            for k in desc_metrics_sum.keys():\n",
    "                res_entry[f\"Desc_{k}\"] = 0.0\n",
    "                \n",
    "        all_results.append(res_entry)\n",
    "        \n",
    "        # 중간 결과 출력\n",
    "        print(f\"  > [Retrieval] Recall@5: {res_entry['Retrieval_Recall@5']:.4f}\")\n",
    "        print(f\"  > [Generation] MCQ Acc: {avg_mcq_acc:.4f}\")\n",
    "        \n",
    "        if desc_count > 0:\n",
    "            print(f\"  > [Generation] Desc BERTScore: {res_entry['Desc_BERTScore']:.4f}\")\n",
    "\n",
    "    # --- 최종 저장 (CSV) ---\n",
    "    if all_results:\n",
    "        df = pd.DataFrame(all_results)\n",
    "        cols = [\"Model\", \"Path\", \"Retrieval_Recall@5\", \"Retrieval_MRR\", \"Retrieval_NDCG\", \n",
    "                \"MCQ_Accuracy\", \"Desc_BERTScore\", \"Desc_Rouge-L\", \"Desc_BLEU-1\", \"Desc_METEOR\", \"Desc_Token_F1\"]\n",
    "        df = df[[c for c in cols if c in df.columns]]\n",
    "        \n",
    "        print(\"\\n=== Final Evaluation Metrics ===\")\n",
    "        print(df)\n",
    "        df.to_csv(RESULT_CSV_PATH, index=False)\n",
    "        print(f\"\\nMetrics saved to: {RESULT_CSV_PATH}\")\n",
    "\n",
    "    # --- 최종 저장 (Word) ---\n",
    "    if qa_logs:\n",
    "        save_logs_to_docx(qa_logs, RESULT_DOCX_PATH)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
