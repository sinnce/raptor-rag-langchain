{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1f57a8f",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "1. Provide a valid `OPENAI_API_KEY` (and optionally `OPENAI_API_BASE` / `GOOGLE_API_KEY`) so embeddings and chat completions can run.\n",
    "2. Store the pdf files you want to use in the `data/raw/` directory.\n",
    "\n",
    "Note) The demo persists a FAISS index under `data/processed/qa_demo`, so rerunning the vector-store cell reuses the cached embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e33547b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workspace root: C:\\Users\\Doyoon\\Desktop\\Doyoon\\2025 Fall\\BKMS1\\Assignment\\Assignment 3\\raptor-rag-langchain\n",
      "QA model: google/gemini-2.5-flash-lite-preview-09-2025\n",
      "OpenAI API key is set\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "ROOT = Path().resolve().parent\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.append(str(ROOT))\n",
    "\n",
    "from src.settings import settings\n",
    "\n",
    "settings.ensure_directories()\n",
    "\n",
    "print(\"Workspace root:\", ROOT)\n",
    "print(\"QA model:\", settings.qa_model)\n",
    "key_source = os.environ.get(\"OPENAI_API_KEY\") or settings.openai_api_key\n",
    "print(\"OpenAI API key is\", \"set\" if key_source else \"missing - set OPENAI_API_KEY before invoking the chain.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "864042b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2191 documents from C:\\Users\\Doyoon\\Desktop\\Doyoon\\2025 Fall\\BKMS1\\Assignment\\Assignment 3\\raptor-rag-langchain\\data\\raw\n"
     ]
    }
   ],
   "source": [
    "from src.ingestion import DocumentIngestion\n",
    "from src.settings import settings\n",
    "\n",
    "\n",
    "raw_data_path = ROOT.joinpath(settings.raw_data_path)\n",
    "\n",
    "ingestor = DocumentIngestion()\n",
    "doc_list = ingestor.load_directory(raw_data_path)\n",
    "print(f\"Loaded {len(doc_list)} documents from {raw_data_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d13b0e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Doyoon\\Desktop\\Doyoon\\2025 Fall\\BKMS1\\Assignment\\Assignment 3\\raptor-rag-langchain\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building new index at C:\\Users\\Doyoon\\Desktop\\Doyoon\\2025 Fall\\BKMS1\\Assignment\\Assignment 3\\raptor-rag-langchain\\data\\processed\\qa_demo\n"
     ]
    }
   ],
   "source": [
    "from src.raptor.tree_builder import TreeBuilder\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "from src.retrieval.vector_store import RaptorVectorStore\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "\n",
    "demo_store_path = ROOT.joinpath(settings.processed_data_path) / \"qa_demo\"\n",
    "demo_store_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "index_file = demo_store_path / \"index.faiss\"\n",
    "\n",
    "if index_file.exists():\n",
    "    vector_store = RaptorVectorStore(persist_directory=demo_store_path)\n",
    "    vector_store.load()\n",
    "    print(\"Loaded existing FAISS index from\", index_file)\n",
    "else:\n",
    "    \n",
    "    tb = TreeBuilder()\n",
    "    raptor_tree = tb.build_from_documents(doc_list)\n",
    "    print(\"Building new index at\", demo_store_path)\n",
    "    vector_store = RaptorVectorStore.from_tree(raptor_tree)\n",
    "    vector_store.save(demo_store_path)\n",
    "#     vector_store.add_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "408a1474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk_size:  1000\n",
      "Chunk_overlap:  50\n",
      "GMM_threshold:  0.1\n",
      "Reduction_dimension:  20\n"
     ]
    }
   ],
   "source": [
    "print(\"Chunk_size: \", ingestor.chunk_size)\n",
    "print(\"Chunk_overlap: \", ingestor.chunk_overlap)\n",
    "print(\"GMM_threshold: \", tb.clustering.threshold)\n",
    "print(\"Reduction_dimension: \", tb.clustering.reduction_dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e3bb5de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the advantage of B+ tree?\n",
      "\n",
      "Answer:\n",
      " The advantage of the B+-tree index structure is that it maintains efficiency despite frequent data insertions and deletions, overcoming the performance degradation seen in index-sequential files which require undesirable reorganization.\n"
     ]
    }
   ],
   "source": [
    "from src.retrieval.rag_chain import RaptorRAGChain\n",
    "\n",
    "rag_chain = RaptorRAGChain(vector_store=vector_store)\n",
    "\n",
    "question = \"What is the advantage of B+ tree?\"\n",
    "print(\"Question:\", question)\n",
    "\n",
    "# context_docs = vector_store.similarity_search(\"RaptorRAGChain\")\n",
    "# for idx, doc in enumerate(context_docs, 1):\n",
    "#     title = doc.metadata.get(\"title\") if isinstance(doc.metadata, dict) else None\n",
    "#     print(f\"\\nContext {idx}: {title or 'Document'}\")\n",
    "#     print(doc.page_content)\n",
    "\n",
    "try:\n",
    "    answer = rag_chain.invoke(question)\n",
    "except Exception as exc:\n",
    "    print(\"\\nQA call failed:\", exc)\n",
    "    answer = None\n",
    "\n",
    "if answer:\n",
    "    print(\"\\nAnswer:\\n\", answer)\n",
    "else:\n",
    "    print(\"\\nAnswer not available; verify your API key and rerun the cell.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98dc8d1",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "1. Experiment with different `settings.qa_model` or `settings.top_k` values by editing `.env` and reloading the notebook.\n",
    "2. When you need deterministic tests, mock `RaptorRAGChain.invoke` instead of calling the live API."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302cada7",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "raptor-rag-langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
